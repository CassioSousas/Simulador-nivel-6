# -*- coding: utf-8 -*-
"""Cópia de wine-quality-dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZfVueo4JQ5YJhIC5-KtRa0rHobfl71hD

**Apresentação do Projeto de Machine Learning para Previsão de Qualidade de Vinhos**

Neste projeto de Machine Learning, a proposta é utilizar o Wine Quality Dataset para desenvolver um modelo preditivo que auxilie uma vinícola a otimizar processos e aprimorar a qualidade de seus produtos. Com base em variáveis físico-químicas (como acidez, teor alcoólico e pH), o modelo permitirá prever a qualidade do vinho antes mesmo de sua finalização, sendo um recurso valioso para guiar decisões estratégicas em diversas etapas da produção.

*Objetivo Principal:*

Criar um sistema preditivo de qualidade de vinhos que forneça insights precisos para aprimorar a seleção de uvas, ajustar o processo de fermentação e garantir a consistência entre as safras, contribuindo para a definição de padrões de qualidade. Esse sistema ajuda a empresa a otimizar a produção, reduzir custos, evitar desperdícios e manter a excelência, fator crucial no mercado competitivo de vinhos.

*Benefícios Esperados:*

Seleção e Processamento Otimizados: Identificar características essenciais para a escolha das melhores uvas e ajuste de fermentação, melhorando a consistência entre safras.

Redução de Custos e Minimização de Desperdícios: Com previsões mais acuradas, a vinícola pode minimizar desperdícios e realizar um uso eficiente de recursos.
Padrão de Excelência: A capacidade de prever a qualidade antes de engarrafar o vinho permite à empresa manter um padrão consistente e de alta qualidade, destacando-se no mercado.

Decisões Estratégicas de Marketing e Precificação: A previsão de qualidade pode ajudar a definir preços adequados e a criar campanhas de marketing alinhadas com a percepção do produto.

*Tecnologias e Técnicas Envolvidas:*

Algoritmos de Machine Learning: Algoritmos supervisionados para previsão de qualidade, como regressão logística e árvores de decisão.

Análise Estatística e Pré-Processamento de Dados: Exploração e limpeza de dados, normalização e transformação para maximizar a performance do modelo.
Validação e Otimização de Modelos: Avaliação do desempenho com métricas adequadas e ajuste de hiperparâmetros.

Este projeto exemplifica a aplicação de técnicas de ciência de dados em um setor tradicional, mostrando como a tecnologia pode ser um diferencial competitivo ao modernizar a produção e reforçar a imagem de qualidade da vinícola.

**Principais Dificuldades**

*Qualidade e Limpeza dos Dados:*

Os dados originais podem apresentar inconsistências, como valores ausentes e outliers significativos, que poderiam distorcer as análises. Para lidar com esses problemas, foi necessário aplicar técnicas de limpeza e normalização, o que exigiu atenção e análise minuciosa.
Identificação de Outliers:

Detectar outliers foi um desafio, pois, em variáveis como acidez e álcool, alguns valores extremos podem representar características reais de alguns vinhos. Por isso, foram usados boxplots para visualizar e decidir quais outliers deveriam ser removidos ou tratados, garantindo que apenas anomalias prejudiciais fossem ajustadas.
Seleção de Variáveis:

Determinar quais variáveis têm maior influência sobre a qualidade do vinho foi complexo. A matriz de correlação e análise de histogramas foram ferramentas valiosas para entender essas relações, mas interpretar essas informações e decidir sobre transformações de variáveis exigiu uma análise cuidadosa.
Avaliação e Escolha de Modelos de Machine Learning:

A escolha de um modelo adequado para prever a qualidade dos vinhos foi desafiadora, uma vez que cada algoritmo apresenta vantagens e desvantagens. Testar diferentes modelos, ajustar hiperparâmetros e selecionar o melhor exigiu experimentação e paciência, especialmente ao equilibrar precisão e complexidade computacional.
Interpretação e Aplicação dos Resultados:

Converter os insights obtidos em ações práticas, como ajustar processos de fermentação ou estratégias de marketing, exigiu uma interpretação cuidadosa das análises. Alinhar os resultados técnicos com aplicações práticas foi essencial para tornar as conclusões viáveis e valiosas.

**Ferramentas Utilizadas**

*Python e Bibliotecas Científicas:*

Pandas: para manipulação, limpeza e análise inicial dos dados. Foi essencial para operações de filtragem e tratamento de valores ausentes.

Numpy: para cálculos matemáticos e manipulação de arrays, auxiliando em operações estatísticas.
Matplotlib e Seaborn: para visualizações de dados, incluindo histogramas, boxplots e mapas de calor, permitindo uma análise visual das distribuições e correlações.

Scikit-Learn: para construção e avaliação dos modelos de machine learning. Essa biblioteca forneceu algoritmos como KNN, Decision Tree, Random Forest e SVM, além de funções para divisão de dados, escalonamento e métricas de avaliação.

*Ferramentas de Machine Learning e Validação de Modelos:*

StandardScaler: para normalização dos dados e assegurar que as variáveis estivessem na mesma escala, evitando que variáveis com valores numéricos maiores dominassem os modelos.

Train Test Split: para dividir os dados entre treinamento e teste, permitindo uma avaliação justa da performance dos modelos e reduzindo o risco de overfitting.
Métricas de Avaliação e Visualizações:

Matriz de Confusão e Relatório de Classificação: utilizadas para avaliar o desempenho dos modelos, ajudando a identificar a precisão das previsões em cada classe e possíveis áreas de melhoria.
Heatmaps de Correlação: para identificar relações entre variáveis e apoiar a seleção de variáveis mais influentes na qualidade.

Essas ferramentas foram fundamentais para a execução do projeto, proporcionando uma análise exploratória robusta, tratamento adequado dos dados e aplicação eficaz dos modelos de machine learning, além de facilitar a interpretação e visualização dos insights obtidos.

**Análise Exploratória de Dados (EDA)**
"""

#Instalando Modelos de Classificação com Scikit-learm
!pip install plotly_express

#Importando as Bibliotecas
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits import mplot3d
from sklearn.metrics import confusion_matrix
import graphviz
import seaborn as sns
import os
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.graph_objects as go

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import train_test_split

from sklearn.linear_model import LogisticRegression

from sklearn.neighbors import KNeighborsClassifier
from sklearn.neighbors import RadiusNeighborsClassifier

from sklearn.naive_bayes import GaussianNB

from sklearn.svm import NuSVC
from sklearn.svm import SVC
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis

from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.ensemble import BaggingClassifier
from sklearn.ensemble import GradientBoostingClassifier

from xgboost import XGBClassifier

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

import warnings
warnings.filterwarnings('ignore')


from sklearn.model_selection import KFold

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, roc_auc_score
lr = LogisticRegression(solver='liblinear')

"""Carregando os Dados"""

dfwine = pd.read_csv('/content/Wine_QT_df19e4d086.csv')
dfwine.head()

#Informações do Dataset
dfwine.info()

#Descrição Estatistica do Dataset
dfwine.describe()

print("Total number of missing values")
print(30 *"-")
print(dfwine.isna().sum())
print(30 *"-")
print("Total missing values")
print(30 * "-")

"""Análise Exploratória"""

# Visualização das Distribuições para cada variável contínua
fig, axes = plt.subplots(3, 4, figsize=(20, 12))
fig.suptitle("Distribuição das Variáveis Contínuas")

columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',
           'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',
           'pH', 'sulphates', 'alcohol', 'quality']

for i, col in enumerate(columns):
    sns.histplot(dfwine[col], kde=True, ax=axes[i // 4, i % 4])
    axes[i // 4, i % 4].set_title(f"Distribuição de {col}")

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

# Gráfico de correlação
plt.figure(figsize=(12, 8))
correlation_matrix = dfwine[columns].corr()
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Matriz de Correlação")
plt.show()

# Boxplots para verificar outliers
fig, axes = plt.subplots(3, 4, figsize=(20, 12))
fig.suptitle("Boxplots das Variáveis Contínuas")

for i, col in enumerate(columns):
    sns.boxplot(data=dfwine, y=col, ax=axes[i // 4, i % 4])
    axes[i // 4, i % 4].set_title(f"Boxplot de {col}")

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

"""**Estatísticas descritivas das variáveis numéricas.**

Distribuições das variáveis com gráficos de histograma e curvas KDE para observar a dispersão.

Matriz de correlação para identificar relações entre as variáveis.
Boxplots para verificar a presença de possíveis outliers.
Esses passos fornecem uma visão inicial abrangente dos dados.

*Conclusão*

Esses gráficos e análises oferecem uma base sólida para compreender o comportamento das variáveis. A partir deles, pode explorar perguntas como:

Há padrões fortes entre as variáveis?

Isso pode ajudar a identificar quais variáveis são mais influentes em quality, por exemplo.

Quais variáveis possuem outliers significativos?

Essa é uma decisão importante para preparar dados para modelagem.

Como as variáveis se distribuem?

Se há variáveis com distribuições muito assimétricas, pode precisar transformá-las (como log ou raiz quadrada) para ajustar os modelos.

"""

#Definindo modelos de Treino e Teste
x = dfwine.drop('quality', axis=1)
y = dfwine['quality']

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

#Escala de Data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.fit_transform(X_test)

#transformando as vareaveis Categoricas ente valores numericos
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

#Classificação de Relatório
def generate_results(model, predictions, name):
    cl_rep = classification_report(y_test, predictions)
    print(f"\nThe Classification Report for " + name +" is:", cl_rep, sep = "\n")
    cm_model = confusion_matrix(y_test, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm_model, annot=True, cmap = 'Blues', annot_kws = {'size': 15}, Square = True)
    plt.title('Matriz de Confusão' + name, size = 20)
    plt.xticks(size = 15)
    plt.yticks(size = 15)
    plt.ylabel('Valores Reais', size = 15)
    plt.xlabel('Valores Preditos', size = 15)
    plt.show()

"""**KNN**"""

knn = KNeighborsClassifier()
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)
acc_knn = knn.score(X_test, y_test)
print("Acurácia do modelo KNN: {:.2f}%".format(acc_knn * 100))

# Treinamento do modelo KNN com n_neighbors = 7
knn_improved = KNeighborsClassifier(n_neighbors=7)
knn_improved.fit(X_train, y_train)

# Previsão e acurácia
y_pred = knn_improved.predict(X_test)
acc_knn_imp = accuracy_score(y_test, y_pred)
print("Acurácia do modelo KNN (n_neighbors = 7): {:.2f}%".format(acc_knn_imp * 100))

# Função para gerar resultados (caso não esteja definida)
def generate_results(model, y_pred, model_name):
    # Matriz de Confusão
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
    plt.title(f"Matriz de Confusão para {model_name}")
    plt.xlabel("Classe Predita")
    plt.ylabel("Classe Real")
    plt.show()

    # Relatório de Classificação
    print(f"Relatório de Classificação para {model_name}:")
    print(classification_report(y_test, y_pred))

# Chamar a função generate_results
generate_results(knn_improved, y_pred, "KNN (n_neighbors = 7)")

"""**SVC**"""

svc = SVC()
svc.fit(X_train, y_train)
y_pred = svc.predict(X_test)
acc_svc = svc.score(X_test, y_test)
print("Acurácia do modelo SVC: {:.2f}%".format(acc_svc * 100))
generate_results(svc, y_pred, "SVC")

"""**DTC**"""

dtc = DecisionTreeClassifier()
dtc.fit(X_train, y_train)
y_pred = dtc.predict(X_test)
acc_dtc = dtc.score(X_test, y_test)
print("Acurácia do modelo Decision Tree Classifier: {:.2f}%".format(acc_dtc * 100))
generate_results(dtc, y_pred, "Decision Tree Classifier")

"""**RFC**"""

rfc = RandomForestClassifier()
rfc.fit(X_train, y_train)
y_pred = rfc.predict(X_test)
acc_rfc = rfc.score(X_test, y_test)
print("Acurácia do modelo Random Forest Classifier: {:.2f}%".format(acc_rfc * 100))
generate_results(rfc, y_pred, "Random Forest Classifier")

"""**Resultados Finais**"""

data = {'KNN (default parameters)': acc_knn * 100,
        'KNN (n_neigbors = 7)': acc_knn_imp * 100,
        'Support Vector Classifier': acc_svc * 100,
        'Decision Tree Classifier': acc_dtc * 100,
        'Radom Forest Classifier': acc_dtc * 100}

data = dict(sorted(data.items(), key=lambda x: x[1], reverse=True))
models = list( data.keys())
score = list (data.values())
fig = plt.figure(figsize = (15,10))
sns.barplot(x = score, y = models)
plt.xlabel('models Used', size = 20)
plt.xticks(size = 12)
plt.ylabel("Score", size = 20)
plt.yticks(size = 12)
plt.title("Comparação de Modelos", size = 20)
plt.show()

"""**Conclusão e Insights**

A análise dos dados de vinho revelou insights cruciais sobre as variáveis que afetam a qualidade do vinho, como acidez, teor alcoólico e pH. Esses fatores, junto com outros, podem ser utilizados para otimizar processos, aprimorar a consistência entre safras e até mesmo definir estratégias de marketing e preços.

Acidez (Fixed Acidity e Volatile Acidity): observou-se que tanto a acidez fixa quanto a volátil estão correlacionadas com a qualidade do vinho, influenciando o sabor e a estabilidade da bebida. Vinhos com níveis de acidez bem balanceados tendem a receber melhores avaliações, sugerindo que o monitoramento e ajuste desses níveis podem melhorar a percepção de qualidade. A seleção de uvas de acidez adequada e a manipulação cuidadosa desses valores durante a fermentação podem resultar em um perfil de sabor mais agradável.

Teor Alcoólico: o teor alcoólico também demonstrou uma correlação significativa com a qualidade percebida. Vinhos com teor alcoólico moderado a alto geralmente obtiveram melhores classificações. Isso sugere que os produtores podem buscar um teor alcoólico específico para cada tipo de vinho, visando não apenas a consistência entre as safras, mas também a valorização do produto final no mercado.

pH e Sulfatos: o pH é um fator essencial para a preservação e longevidade do vinho, e sulfatos atuam como conservantes. A análise demonstrou que vinhos com pH e níveis de sulfatos balanceados apresentam melhor qualidade, indicando que a gestão desses parâmetros pode aumentar a estabilidade e a durabilidade do produto. Isso é especialmente importante para vinhos destinados a armazenamento prolongado e pode ser um diferencial de marketing.

Qualidade e Outros Parâmetros: a análise de correlação mostrou que variáveis como açúcar residual e dióxido de enxofre total também afetam a qualidade. Controlar esses elementos pode ajudar a atender a preferências de paladar mais específicas, oferecendo vinhos mais doces ou com menos conservantes conforme o perfil do consumidor.

Desempenho dos Modelos:

A classificação dos vinhos usando modelos como KNN, SVC, Decision Tree e Random Forest mostrou que o Random Forest Classifier se destacou com a maior acurácia, enquanto o KNN com n_neighbors = 7 também apresentou bom desempenho.
A escolha do modelo de classificação mais preciso ajuda a prever a qualidade com base em variáveis químicas, facilitando decisões rápidas sobre ajustes na produção e garantindo consistência na qualidade.
Aplicações Práticas
Esses insights podem ser aplicados diretamente para:

Seleção de Uvas: escolher uvas com características ideais para os níveis de acidez e açúcar desejados.
Ajustes nos Processos de Fermentação: otimizar o teor alcoólico e o pH durante a fermentação para obter um produto mais estável e de alta qualidade.
Consistência entre Safras: garantir que as variáveis-chave estejam alinhadas para manter a qualidade padrão a cada safra, o que fideliza consumidores.
Marketing e Definição de Preços: vinhos com características premium, como teor alcoólico específico e pH balanceado, podem ser vendidos a um preço superior e direcionados a um público-alvo específico.
Esses resultados fornecem uma base sólida para aprimorar processos de produção e garantir que o produto final atenda às expectativas de qualidade do mercado. A integração desses insights em processos futuros permitirá otimizações tanto em termos de eficiência produtiva quanto de valorização no mercado consumidor.
"""